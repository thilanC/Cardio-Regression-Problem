{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\University\\Extra Courses\\DL workshop\\Python Practicles\\Cardio Regression Problem\\WebApp\\data\\cardio_dataset.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[:,0:7]\n",
    "target=df[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "target=np.reshape(target, (-1,1))\n",
    "\n",
    "scaler_data = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "scaler_data.fit(data)\n",
    "scaler_target.fit(target)\n",
    "\n",
    "data_scaled=scaler_data.transform(data)\n",
    "target_scaled=scaler_target.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_scaled,target_scaled,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               1024      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,941\n",
      "Trainable params: 9,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "import keras.optimizers as optimizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model1=models.Sequential()\n",
    "model1.add(layers.Dense(128,input_dim=7,activation='tanh',kernel_initializer='normal'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(layers.Dense(64,activation='tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(layers.Dense(10,activation='tanh'))\n",
    "model1.add(layers.Dense(1,activation='linear'))\n",
    "\n",
    "model1.compile(optimizer='adam',loss='mse',metrics=['mse','mae'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import keras\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback): #after 1 epoch print r2 score\n",
    "\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        predicted_result=model1.predict(X_test)\n",
    "        r2=r2_score(y_test,predicted_result)\n",
    "        print('epoch',epoch,'- r2 score:',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint #save model\n",
    "\n",
    "checkpoint = ModelCheckpoint('models/model-{epoch:03d}.model',monitor='val_loss',save_best_only=True,mode='auto') #here we try to save best model\n",
    "#saved in model folder,if val loss less than previous epoch then save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/167 [===========================>..] - ETA: 0s - loss: 0.0161 - mse: 0.0161 - mae: 0.0903INFO:tensorflow:Assets written to: models\\model-001.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 0 - r2 score: 0.7281626483612598\n",
      "167/167 [==============================] - 4s 20ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0892 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0570\n",
      "Epoch 2/200\n",
      "155/167 [==========================>...] - ETA: 0s - loss: 0.0086 - mse: 0.0086 - mae: 0.0653INFO:tensorflow:Assets written to: models\\model-002.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 1 - r2 score: 0.7434533818773237\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0650 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0560\n",
      "Epoch 3/200\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.0076 - mse: 0.0076 - mae: 0.0621INFO:tensorflow:Assets written to: models\\model-003.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 2 - r2 score: 0.7455386394109538\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0620 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0537\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0079 - mse: 0.0079 - mae: 0.\n",
      "epoch 3 - r2 score: 0.7378147779235831\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0622 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0532\n",
      "Epoch 5/200\n",
      "162/167 [============================>.] - ETA: 0s - loss: 0.0069 - mse: 0.0069 - mae: 0.0590INFO:tensorflow:Assets written to: models\\model-005.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 4 - r2 score: 0.775129311119997\n",
      "167/167 [==============================] - 3s 16ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0591 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0536\n",
      "Epoch 6/200\n",
      "151/167 [==========================>...] - ETA: 0s - loss: 0.0061 - mse: 0.0061 - mae: 0.0540INFO:tensorflow:Assets written to: models\\model-006.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 5 - r2 score: 0.8126746439088829\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0539 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0405\n",
      "Epoch 7/200\n",
      "156/167 [===========================>..] - ETA: 0s - loss: 0.0054 - mse: 0.0054 - mae: 0.0496INFO:tensorflow:Assets written to: models\\model-007.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 6 - r2 score: 0.8360511737914217\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0496 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0384\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0051 - mse: 0.0051 - mae: 0.\n",
      "epoch 7 - r2 score: 0.8338418097428791\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0482 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0395\n",
      "Epoch 9/200\n",
      "153/167 [==========================>...] - ETA: 0s - loss: 0.0049 - mse: 0.0049 - mae: 0.0467INFO:tensorflow:Assets written to: models\\model-009.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 8 - r2 score: 0.8448214650104726\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0468 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0384\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0049 - mse: 0.0049 - mae: 0.\n",
      "epoch 9 - r2 score: 0.8291477181622577\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0468 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0444\n",
      "Epoch 11/200\n",
      "151/167 [==========================>...] - ETA: 0s - loss: 0.0046 - mse: 0.0046 - mae: 0.0456INFO:tensorflow:Assets written to: models\\model-011.model\\assets\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "epoch 10 - r2 score: 0.8463541746449526\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0458 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0376\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0046 - mse: 0.0046 - mae: 0.\n",
      "epoch 11 - r2 score: 0.8415344074111006\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0452 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0409\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0051 - mse: 0.0051 - mae: 0.\n",
      "epoch 12 - r2 score: 0.8225312781957186\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0481 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0426\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0050 - mse: 0.0050 - mae: 0.\n",
      "epoch 13 - r2 score: 0.8413666121430128\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0473 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0412\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0046 - mse: 0.0046 - mae: 0.\n",
      "epoch 14 - r2 score: 0.845641007651452\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0450 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0392\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0046 - mse: 0.0046 - mae: 0.\n",
      "epoch 15 - r2 score: 0.8312216676354022\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0458 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0407\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0046 - mse: 0.0046 - mae: 0.\n",
      "epoch 16 - r2 score: 0.8309992881771017\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0457 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0379\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0045 - mse: 0.0045 - mae: 0.\n",
      "epoch 17 - r2 score: 0.8458929450790967\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0452 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0405\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0044 - mse: 0.0044 - mae: 0.\n",
      "epoch 18 - r2 score: 0.844848858039956\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0450 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0363\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0045 - mse: 0.0045 - mae: 0.\n",
      "epoch 19 - r2 score: 0.8264860232233544\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0451 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0479\n",
      "Epoch 21/200\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.0047 - mse: 0.0047 - mae: 0.0466INFO:tensorflow:Assets written to: models\\model-021.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 20 - r2 score: 0.8492717639759841\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0464 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0375\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0045 - mse: 0.0045 - mae: 0.\n",
      "epoch 21 - r2 score: 0.8448825021631325\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0448 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0404\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0044 - mse: 0.0044 - mae: 0.\n",
      "epoch 22 - r2 score: 0.8444269781990841\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0441 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0382\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0044 - mse: 0.0044 - mae: 0.\n",
      "epoch 23 - r2 score: 0.8469666290548399\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0437 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0398\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0043 - mse: 0.0043 - mae: 0.\n",
      "epoch 24 - r2 score: 0.8449387039311809\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0444 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0393\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0043 - mse: 0.0043 - mae: 0.\n",
      "epoch 25 - r2 score: 0.8458554296790962\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0442 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0396\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0043 - mse: 0.0043 - mae: 0.\n",
      "epoch 26 - r2 score: 0.8383939818449581\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0441 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0400\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0044 - mse: 0.0044 - mae: 0.\n",
      "epoch 27 - r2 score: 0.8490391259330979\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0438 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0387\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0043 - mse: 0.0043 - mae: 0.\n",
      "epoch 28 - r2 score: 0.8468826896597563\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0440 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0386\n",
      "Epoch 30/200\n",
      "165/167 [============================>.] - ETA: 0s - loss: 0.0046 - mse: 0.0046 - mae: 0.0456INFO:tensorflow:Assets written to: models\\model-030.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 29 - r2 score: 0.8525321913100644\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0455 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0371\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0043 - mse: 0.0043 - mae: 0.\n",
      "epoch 30 - r2 score: 0.8485704400268506\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0437 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0360\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0042 - mse: 0.0042 - mae: 0.\n",
      "epoch 31 - r2 score: 0.8469825398539642\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0433 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0400\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0044 - mse: 0.0044 - mae: 0.\n",
      "epoch 32 - r2 score: 0.8479699744841336\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0441 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0402\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0043 - mse: 0.0043 - mae: 0.\n",
      "epoch 33 - r2 score: 0.8509659887605485\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0431 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0351\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 34 - r2 score: 0.844398691459709\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0430 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0417\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 35 - r2 score: 0.8462607929966364\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0434 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0394\n",
      "Epoch 37/200\n",
      "164/167 [============================>.] - ETA: 0s - loss: 0.0041 - mse: 0.0041 - mae: 0.0424INFO:tensorflow:Assets written to: models\\model-037.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 36 - r2 score: 0.8546393445781952\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0423 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0364\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 37 - r2 score: 0.8506261691223933\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0427 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0378\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 38 - r2 score: 0.8488441675117773\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0424 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0383\n",
      "Epoch 40/200\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0041 - mae: 0.0425INFO:tensorflow:Assets written to: models\\model-040.model\\assets\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "epoch 39 - r2 score: 0.8557142610072752\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0425 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0360\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 40 - r2 score: 0.8489506615685473\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0424 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0352\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0042 - mse: 0.0042 - mae: 0.\n",
      "epoch 41 - r2 score: 0.8503327744772242\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0433 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0408\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 42 - r2 score: 0.841547909346302\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0427 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0371\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 43 - r2 score: 0.8453593140567314\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0429 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0370\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 44 - r2 score: 0.8519354777972921\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0418 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0371\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 45 - r2 score: 0.852619045432042\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0415 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0365\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 46 - r2 score: 0.8456463374304374\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0416 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0425\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0044 - mse: 0.0044 - mae: 0.\n",
      "epoch 47 - r2 score: 0.8506577612776925\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0436 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0358\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 48 - r2 score: 0.8483796732792557\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0417 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0353\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 49 - r2 score: 0.842888739436289\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0417 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0382\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 50 - r2 score: 0.8282180226471343\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0411 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0416\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 51 - r2 score: 0.8500024774489463\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0422 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0352\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 52 - r2 score: 0.8524128465617581\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0412 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0361\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 53 - r2 score: 0.8545681572792078\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0423 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0346\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 54 - r2 score: 0.8356275979165246\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0410 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0355\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0040 - mse: 0.0040 - mae: \n",
      "epoch 55 - r2 score: 0.8515296381965312\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0363\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0040 - mse: 0.0040 - mae: \n",
      "epoch 56 - r2 score: 0.8300397519764938\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0417 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0402\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 57 - r2 score: 0.8516379628846418\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0414 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0362\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 58 - r2 score: 0.8548235979330597\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0418 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0345\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 59 - r2 score: 0.8486060258624234\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0407 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0352\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 60 - r2 score: 0.8542221378023385\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0415 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0357\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 61 - r2 score: 0.8525653380501519\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0414 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0365\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 62 - r2 score: 0.8522002230777934\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0412 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0380\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 63 - r2 score: 0.8543637479970719\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0407 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0365\n",
      "Epoch 65/200\n",
      "145/167 [=========================>....] - ETA: 0s - loss: 0.0039 - mse: 0.0039 - mae: 0.0408INFO:tensorflow:Assets written to: models\\model-065.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 64 - r2 score: 0.8559918165317465\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0406 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0360\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 65 - r2 score: 0.8525350065229017\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0408 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0352\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 66 - r2 score: 0.8186297266301918\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0410 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0420\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0041 - mse: 0.0041 - mae: 0.\n",
      "epoch 67 - r2 score: 0.8556602815167011\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0415 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0356\n",
      "Epoch 69/200\n",
      "150/167 [=========================>....] - ETA: 0s - loss: 0.0040 - mse: 0.0040 - mae: 0.0412INFO:tensorflow:Assets written to: models\\model-069.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 68 - r2 score: 0.8571018969349604\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0413 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0348\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 69 - r2 score: 0.848303621275561\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0411 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0381\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 70 - r2 score: 0.8552313305158035\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0407 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0369\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 71 - r2 score: 0.8553305747092904\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0409 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0339\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 72 - r2 score: 0.8518995010564001\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0383\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 73 - r2 score: 0.8557912485322936\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0405 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0349\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 74 - r2 score: 0.8489818272069651\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0416 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0345\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 75 - r2 score: 0.8471694006743\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0349\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 76 - r2 score: 0.8541376902496955\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0397 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0342\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 77 - r2 score: 0.8549487139109481\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0408 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0377\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 78 - r2 score: 0.8527819377193849\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0409 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0359\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 5ms/step loss: 0.0040 - mse: 0.0040 - mae\n",
      "epoch 79 - r2 score: 0.8480008903082507\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0406 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0358\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 80 - r2 score: 0.8542595191847561\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0345\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 81 - r2 score: 0.8532393626726097\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0357\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 82 - r2 score: 0.843705490750352\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0365\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 83 - r2 score: 0.830250809970694\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0399 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0386\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 84 - r2 score: 0.8567669421094749\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0411 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0362\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 85 - r2 score: 0.8515865969089168\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0410 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0353\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 86 - r2 score: 0.8505781302593429\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0403 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0364\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0039 - mse: 0.0039 - mae: \n",
      "epoch 87 - r2 score: 0.8542051815314284\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0405 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0349\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 88 - r2 score: 0.8504199294149681\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0359\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 89 - r2 score: 0.8543753033739819\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0403 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0356\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 90 - r2 score: 0.8547979746194492\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0399 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0360\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 91 - r2 score: 0.8554506298980389\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0348\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 92 - r2 score: 0.8519046551642993\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0401 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0380\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 93 - r2 score: 0.8535509889382131\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0356\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 94 - r2 score: 0.8527175395929614\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0415 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0351\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 95 - r2 score: 0.8538793773268777\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0401 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0351\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 96 - r2 score: 0.8513589809099729\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0403 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0360\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 97 - r2 score: 0.8558853400667754\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0401 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0347\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 98 - r2 score: 0.8482628709841591\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0359\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 99 - r2 score: 0.8549633275992914\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0341\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 100 - r2 score: 0.8554607397000342\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0399 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0345\n",
      "Epoch 102/200\n",
      "160/167 [===========================>..] - ETA: 0s - loss: 0.0039 - mse: 0.0039 - mae: 0.0404INFO:tensorflow:Assets written to: models\\model-102.model\\assets\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "epoch 101 - r2 score: 0.8575174350239763\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0348\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 102 - r2 score: 0.8475438281735905\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0352\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 103 - r2 score: 0.8567474191676867\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0341\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 104 - r2 score: 0.8423805440143377\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0368\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 105 - r2 score: 0.8531356437796589\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0405 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0359\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 106 - r2 score: 0.8544173120670775\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0403 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0376\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 107 - r2 score: 0.8481344100525574\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0381\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 108 - r2 score: 0.8458672839454507\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0395 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0367\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 4ms/step loss: 0.0039 - mse: 0.0039 - mae\n",
      "epoch 109 - r2 score: 0.844710286910433\n",
      "167/167 [==============================] - 1s 9ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0395 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0353\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0039 - mse: 0.0039 - mae: \n",
      "epoch 110 - r2 score: 0.8446754508951306\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0369\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 111 - r2 score: 0.8542145002327604\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0344\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 112 - r2 score: 0.8427558018563545\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0370\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 113 - r2 score: 0.8517850191884143\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0401 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0342\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 114 - r2 score: 0.8500352445285019\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0403 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0381\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 115 - r2 score: 0.8516951656864182\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0350\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 116 - r2 score: 0.8564245649106369\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0392 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0358\n",
      "Epoch 118/200\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0038 - mae: 0.0399INFO:tensorflow:Assets written to: models\\model-118.model\\assets\n",
      "42/42 [==============================] - 0s 1ms/step\n",
      "epoch 117 - r2 score: 0.858207073390728\n",
      "167/167 [==============================] - 2s 15ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0399 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0347\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 118 - r2 score: 0.8484682114045746\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0349\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 119 - r2 score: 0.857901346043992\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0393 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0343\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 120 - r2 score: 0.8514129269529866\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0397 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0352\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 121 - r2 score: 0.8551511047739292\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0390 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0348\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 1ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 122 - r2 score: 0.8570745739424201\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0344\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 123 - r2 score: 0.8578189004262473\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0397 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0370\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 124 - r2 score: 0.8547165300250011\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0395 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0384\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 125 - r2 score: 0.855801582455872\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0401 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0346\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 126 - r2 score: 0.8549941857719537\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0392 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0366\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 127 - r2 score: 0.8500120112474762\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0390 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0347\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0038 - mse: 0.0038 - mae: \n",
      "epoch 128 - r2 score: 0.8513507724780665\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0352\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0040 - mse: 0.0040 - mae: 0.\n",
      "epoch 129 - r2 score: 0.854156248442204\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0407 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0345\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 130 - r2 score: 0.8533113117907967\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0391 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0355\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 131 - r2 score: 0.8527293009492611\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0392 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0347\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 132 - r2 score: 0.8554393911357675\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0353\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 133 - r2 score: 0.8552286168450016\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0394 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0344\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 134 - r2 score: 0.8559947876895798\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0393 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0351\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 135 - r2 score: 0.8440585726870936\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0396 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0358\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 136 - r2 score: 0.8551230595873255\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0393 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0347\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 137 - r2 score: 0.8512763987458886\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0397 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0358\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 138 - r2 score: 0.8551874963588088\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0400 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0353\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 139 - r2 score: 0.8539550074115625\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0391 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0352\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 140 - r2 score: 0.8402217352206094\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0390 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0370\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 141 - r2 score: 0.8516253290749091\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0384 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0373\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 4ms/step loss: 0.0039 - mse: 0.0039 - mae: \n",
      "epoch 142 - r2 score: 0.8508206880969419\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0400 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0349\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 143 - r2 score: 0.8325346972521245\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0389 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0378\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 144 - r2 score: 0.8565071023572792\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0392 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0343\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 145 - r2 score: 0.8548978290865761\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0399 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0349\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 146 - r2 score: 0.8437534328760364\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0390 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0370\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 147 - r2 score: 0.8548458163369913\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0396 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0342\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 148 - r2 score: 0.8345844185961662\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0391 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0365\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 149 - r2 score: 0.8554817551741346\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0398 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0373\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 150 - r2 score: 0.8550024143890442\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0394 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0358\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 151 - r2 score: 0.8537173585608477\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0395 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0351\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0037 - mse: 0.0037 - mae: \n",
      "epoch 152 - r2 score: 0.8526009765526199\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0392 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0371\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 153 - r2 score: 0.8517893124186895\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0388 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0348\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 154 - r2 score: 0.8458017093789537\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0395 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0417\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 155 - r2 score: 0.8557165913242688\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0368\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 156 - r2 score: 0.8532700521321571\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0392 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0341\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 157 - r2 score: 0.856723145675634\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0352\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 158 - r2 score: 0.8492578953855997\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0390 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0387\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 159 - r2 score: 0.8562443570776402\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0394 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0364\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 160 - r2 score: 0.8455338192350884\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0392 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0388\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0039 - mse: 0.0039 - mae: 0.\n",
      "epoch 161 - r2 score: 0.851694157243335\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0403 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0357\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 162 - r2 score: 0.8534469968650981\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0378\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 163 - r2 score: 0.8544383968207525\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0390 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0347\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 164 - r2 score: 0.8543730937391525\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0392 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0373\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 165 - r2 score: 0.8553676790417604\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0388 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0350\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 166 - r2 score: 0.8497609108409521\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0393 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0369\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 167 - r2 score: 0.85011172279674\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0389 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0365\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 168 - r2 score: 0.8499030802528549\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0393 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0345\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 169 - r2 score: 0.8575153596527383\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0354\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 170 - r2 score: 0.8349048539600752\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0385 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0448\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 171 - r2 score: 0.8500404733271844\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0392 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0362\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 172 - r2 score: 0.8471495965144894\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0396 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0356\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 173 - r2 score: 0.849943911267262\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0385 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0372\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 174 - r2 score: 0.8461957741941151\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0391 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0362\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 175 - r2 score: 0.8447695722179632\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0388 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0366\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 176 - r2 score: 0.8512257985277074\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0390 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0343\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 177 - r2 score: 0.8535963950269112\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0389 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0361\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 178 - r2 score: 0.8530735798233365\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0389 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0347\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 179 - r2 score: 0.8518406542413435\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0391 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0396\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 180 - r2 score: 0.8534209280730369\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0387 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0348\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 181 - r2 score: 0.8537805337809029\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0391 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0356\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 182 - r2 score: 0.8524196122750296\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0390 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0380\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 183 - r2 score: 0.8515824934683186\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0387 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0355\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 184 - r2 score: 0.8498687107665228\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0391 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0370\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 185 - r2 score: 0.8561219507413185\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0392 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0348\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 186 - r2 score: 0.8520743167345117\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0391 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0347\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0036 - mse: 0.0036 - mae: \n",
      "epoch 187 - r2 score: 0.8517266216022941\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0388 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0349\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 188 - r2 score: 0.8467941466873787\n",
      "167/167 [==============================] - 2s 9ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0386 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0364\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 189 - r2 score: 0.855389882815481\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0388 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0361\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 190 - r2 score: 0.8436280662336227\n",
      "167/167 [==============================] - 1s 7ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0392 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0364\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 191 - r2 score: 0.8517564657034536\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0389 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0354\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 192 - r2 score: 0.8479657704509842\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0391 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0364\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 193 - r2 score: 0.8532881715748819\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0385 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0351\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 194 - r2 score: 0.853328717722637\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0389 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0348\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0037 - mse: 0.0037 - mae: 0.\n",
      "epoch 195 - r2 score: 0.8546478476216033\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0387 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0347\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0038 - mse: 0.0038 - mae: 0.\n",
      "epoch 196 - r2 score: 0.8524879370613969\n",
      "167/167 [==============================] - 1s 6ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0394 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0365\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 197 - r2 score: 0.8547955654410593\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0388 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0379\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 3ms/step loss: 0.0037 - mse: 0.0037 - mae: \n",
      "epoch 198 - r2 score: 0.8511742518797172\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0386 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0356\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 2ms/step loss: 0.0036 - mse: 0.0036 - mae: 0.\n",
      "epoch 199 - r2 score: 0.8537759646274884\n",
      "167/167 [==============================] - 1s 8ms/step - loss: 0.0036 - mse: 0.0036 - mae: 0.0382 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0345\n"
     ]
    }
   ],
   "source": [
    "history=model1.fit(X_train,y_train,epochs=200,validation_data=(X_test,y_test),callbacks=[checkpoint,CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history.history['loss'],label='loss')\n",
    "plt.plot(model1.history.history['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_target.sav']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler_data,'sacler_data.sav') #scale down,up models save\n",
    "joblib.dump(scaler_target,'scaler_target.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLPrac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
